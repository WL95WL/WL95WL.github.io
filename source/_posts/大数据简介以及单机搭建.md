---
title: 大数据
date: 2020-01-13 15:28:27
tags: bigdata
comment: true
---

# 大数据

**大数据特点**

`5V特点：Volume（大量）、Velocity（高速）、Variety（多样）、Value（价值）Veracity（真实性）` 

`数据量级大`/`数据时效性|数据处理速度快`/`数据多样性`/`数据有价值-降噪`

**大数据与传统的数据技术的差别**

  1、数据规模大：传统数据技术主要是利用现有存在关系性数据库中的数据，对这些数据进行分析、处理，找到一些关联，并利用数据关联性创造价值。这些数据的规模相对较小，可以利用数据库的分析工具处理。而大数据的数据量非常大，不可能利用数据库分析工具分析。

​    2、非结构化数据：传统数据主要在关系性数据库中分析，而大数据可以处理图像、声音、文件等非结构化数据。

3、处理方式不同：因为数据规模大、非结构化数据这两方面因素，导致大数据在分析时不能取全部数据做分析。大数据分析时如何选取数据?这就需要根据一些标签来抽取数据。所以大数据处理过程中，比传统数据增加了一个过程Stream。就是在写入数据的时候，在数据上打一个标签，之后在利用大数据的时候，根据标签抽取数据。

**大数据面临问题?**

`存储`:单机存储有限,如何解决海量数据存储?

`分析`:如何在合理时间范围内对数据完成节本运算?

**分布式**:通常将`夸机器`/`跨进程`/`跨虚拟机`架构称为分布式架构,因为硬件垂直提升成本较高且不可控,相比较垂直提升硬件水平扩展成本较低,能够使得投入和产出趋近于线性.

## 大数据分析方案哪些?

`Map Reduce`:代表基于磁盘离线大数据静态批处理框架-延迟较高30分钟+

`Spark `:代表基于内存近实时(离线)大数据静态批处理框架-几乎是Map Reduce的10~100倍速度

`Storm|Spark Streaming| Flink|Kafka Stream`:实时的流(流程)处理框架,达到对记录级别的数据显示毫秒级处理.

# Hadoop

Hadoop是在2006年雅虎从Nutch(给予Java爬虫框架)工程中剥离一套分布式的解决方案.该方案参考了Goggle的`GFS(Google File System)`和MapReduce论文,当时发布的版本称为Hadoop-1.x,并且在2010年雅虎对Hadoop做又一次升级,该次升级的目的是优化了Hadoop的MapReduce框架,使得Hadoop更加易用,用户只需要少许配置,就可以使用hadoop实现海量数据存储和大规模数据集的分析.`一个由Apache基金会所开发的分布式系统基础架构。`

==HDFS==: hadoop distribute filesysterm

==Map Reduce==:hadoop中的分布式计算框架,实现对海量数据并行分析和计算.

## Hadoop Eco System (hadoop的生态系统圈)

`HDFS`:分布式存储系统

`mapreduce`:并行计算框架

`hbase`:基于HDFS之上一款NoSQL数据库(名符其实海量数据存储解决方案)

`hive`:会一款SQL的解析引擎,可以将SQL翻译成MapReduce任务,将任务提交给MapReduce框架.

`flume`:分布式日志采集系统,用于搜集海量数据,并且存储到HDFS/Hbase.

`Kafka`:分布式消息系统,实现分布系统间解耦和海量数据的缓冲.

`zookeeper`:分布式协调服务,用于`服务注册中心`/`配置中心`/`集群选举`/`状态监测`/`分布式锁`



## HDFS 环境搭建(伪分布式单机-测试)

- Window 安装64 bit CentOS(需要额外开启Intel 虚拟化技术)



- 安装JDK

  ```shell
  一
  1、查询要安装jdk的版本：
  命令：yum -y list java*
  2、安装jdk
  命令：yum install -y java-1.8.0-openjdk.x86_64
  3、查询jdk版本
  命令：java -version
  默认给安装到usr/lib/jvm/
  二、解压（常用）
   rpm -ivh jdk-8u171-linux-x64.rpm 
  ```

- 安装JDK配置`JAVA_HOME`

```shell
vi /etc/profile #系统变量
[root@CentOS ~]# vi /root/.bashrc # 用户变量
JAVA_HOME=/usr/java/latest
PATH=$PATH:$JAVA_HOME/bin
CLASSPATH=.
export JAVA_HOME
export PATH
export CLASSPATH
[root@CentOS ~]# source /root/.bashrc 
[root@CentOS ~]# jps
1495 Jps
```

> 

> 参考:https://blog.csdn.net/yuzongtao/article/details/44700927

- 尝试`[root@CentOS ~]# yum install lrzsz -y`组件,如果用户将JAVA_HOME配置在系统变量中`/etc/profile`需要在安装hadoop时候额外配置`etc/hadoop/hadoop-env.sh `,因此推荐配置在用户变量中.
- 配置主机名和IP映射关系`/etc/hosts`

```shell
[root@CentOS ~]# vi /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.169.139 CentOS
```

> 在分布式系统中很多服务都是以主机名标示节点,因此配置IP和主机名的映射关系.用户可以查看以下文件

```shell
[root@CentOS ~]# cat /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=CentOS
```

- 关闭防火墙服务centos6
- centOS7关闭防火墙：<https://blog.csdn.net/TTTZZZTTTZZZ/article/details/81483204>

```shell
[root@CentOS ~]# service iptables stop #关闭服务
iptables: Setting chains to policy ACCEPT: filter [  OK  ]
iptables: Flushing firewall rules: [  OK  ]
iptables: Unloading modules: [  OK  ]
[root@CentOS ~]# chkconfig iptables off #关闭开机自起
[root@CentOS ~]# chkconfig --list | grep iptables 
iptables        0:off   1:off   2:off   3:off   4:off   5:off   6:off
```

> 因为搭建分布式服务之间可能会产生相互的调度,为了保证正常的通信,一般需要关闭防火墙.

- 配置主机SSH免密码认证(密匙)

SSH 为 Secure Shell 的缩写，SSH 为建立在应用层基础上的安全协议，专为远程登录会话和其他网络服务提供安全性的协议。

==*基于口令的安全验证*==:基于口令`用户名`/`密码`

==*基于密匙的安全验证*==:

需要依靠密匙，也就是你必须为自己创建一对密匙，并把公用密匙放在需要访问的服务器上。如果你要连接到SSH服务器上，客户端软件就会向服务器发出请求，请求用你的密匙进行安全验证。服务器收到请求之后，先在该服务器上你的主目录下寻找你的公用密匙，然后把它和你发送过来的公用密匙进行比较。如果两个密匙一致，服务器就用公用密匙加密“质询”（challenge）并把它发送给客户端软件。客户端软件收到“质询”之后就可以用你的私人密匙解密再把它发送给服务器。

```shell
[root@CentOS ~]# ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa): 
Created directory '/root/.ssh'.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:
c3:b7:c4:e3:5e:6f:db:69:48:23:1e:f7:81:9b:d1:8e root@CentOS
The key's randomart image is:
+--[ RSA 2048]----+
|                 |
|                 |
|                 |
|       . .       |
|        S =   o  |
|         = = * o |
|          + * X .|
|         . o E.=.|
|          .  .+o.|
+-----------------+
[root@CentOS ~]# ssh-copy-id CentOS
The authenticity of host 'centos (192.168.169.139)' can't be established.
RSA key fingerprint is f0:63:ed:d6:21:3b:b5:47:ad:e2:7f:98:bd:8f:54:94.
Are you sure you want to continue connecting (yes/no)? `yes`
Warning: Permanently added 'centos,192.168.169.139' (RSA) to the list of known hosts.
root@centos's password:`****` 
Now try logging into the machine, with "ssh 'CentOS'", and check in:

  .ssh/authorized_keys

to make sure we haven't added extra keys that you weren't expecting.

```

- HADOOP HDFS安装与配置

> 参考:http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html

*解压并且配置HADOOP_HOME*

```shell
[root@CentOS ~]# tar -zxf hadoop-2.6.0_x64.tar.gz -C /usr/

HADOOP_HOME=/usr/hadoop-2.6.0
JAVA_HOME=/usr/java/latest
PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
CLASSPATH=.
export JAVA_HOME
export PATH
export CLASSPATH
export HADOOP_HOME

[root@CentOS ~]# source /root/.bashrc 
[root@CentOS ~]# echo $HADOOP_HOME
```

> `HADOOP_HOME`环境变量被第三方产品所依赖例如:`hbase`/`hive`/`flume`/`Spark`在集成Hadoop的时候,是通过读取HADOOP_HOME环境变量确定HADOOP位置.

*配置etc/hadoop/core-site.xml*

```xml
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://CentOS:9000</value>
</property>

<property>
        <name>hadoop.tmp.dir</name>
        <value>/usr/hadoop-2.6.0/hadoop-${user.name}</value>
</property>
```

*配置etc/hadoop/hdfs-site.xml*

```xml
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>

```

*配置etc/hadoop/slaves*

```reStructuredText
CentOS
```

- 启动HDFS

*1.如果是第一次启动HDFS,需要格式化`namenode`*

```shell
[root@CentOS ~]# hdfs namenode -format
...
19/01/02 20:19:37 INFO common.Storage: Storage directory /usr/hadoop-2.6.0/hadoop-root/dfs/name has been successfully formatted.
...
再次启动需要删除/usr/hadoop-2.6.0/hadoop-root/
```

> 格式化成功后,用户可以看到以下目录结构

```reStructuredText
1.安装插件 yum install -y tree
[root@CentOS ~]# tree /usr/hadoop-2.6.0/hadoop-root/
/usr/hadoop-2.6.0/hadoop-root/
└── dfs
    └── name
        └── current
            ├── fsimage_0000000000000000000
            ├── fsimage_0000000000000000000.md5
            ├── seen_txid
            └── VERSION
```

*2.启动HDFS服务*

```shell
[root@CentOS ~]# start-dfs.sh 
Starting namenodes on [CentOS]
CentOS: namenode running as process 1846. Stop it first.
CentOS: starting datanode, logging to /usr/hadoop-2.6.0/logs/hadoop-root-datanode-CentOS.out
Starting secondary namenodes [0.0.0.0]
The authenticity of host '0.0.0.0 (0.0.0.0)' can't be established.
RSA key fingerprint is f0:63:ed:d6:21:3b:b5:47:ad:e2:7f:98:bd:8f:54:94.
Are you sure you want to continue connecting (yes/no)? yes
0.0.0.0: Warning: Permanently added '0.0.0.0' (RSA) to the list of known hosts.
0.0.0.0: starting secondarynamenode, logging to /usr/hadoop-2.6.0/logs/hadoop-root-secondarynamenode-CentOS.out
[root@CentOS ~]# jps
2370 Jps
2133 DataNode
1846 NameNode
2267 SecondaryNameNode
[root@CentOS ~]# stop-dfs.sh 
Stopping namenodes on [CentOS]
CentOS: stopping namenode
CentOS: stopping datanode
Stopping secondary namenodes [0.0.0.0]
0.0.0.0: stopping secondarynamenode
```

> 或者用户可以访问浏览器:http://192.168.169.139:50070
>
> <https://www.cnblogs.com/zyanrong/p/11774997.html>

```shell
[root@CentOS ~]# hdfs dfs -put /root/jdk-8u171-linux-x64.rpm  /
[root@CentOS ~]# hdfs dfs -ls  /
Found 1 items
-rw-r--r--   1 root supergroup  175262413 2019-01-02 20:29 /jdk-8u171-linux-x64.rpm
```

> 
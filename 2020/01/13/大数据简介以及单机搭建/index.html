<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>大数据简介以及单机搭建 | Black eight</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="WL">
  <meta name="keywords" content>
  <meta name="description" content="Mr. Worldwide I just want to welcome everybody to my life It's heaven on earth but it's one hell of a ride">
  <script id="hexo-configurations">
  var CONFIG = {
    root: '/',
    theme: 'hexo-theme-lx',
    version: '1.4.5',
    localsearch:{
      "enable": true,
      "trigger": "auto",
      "top_n_per_article": 1,
      "unescape": false,
      "preload": false
      },
    path: 'search.xml'
  };
</script>

  <link rel="shortcut icon" href="/favicon.ico">
  <link rel="stylesheet" href="/css/main.css">
  <script src="/js/jquery.min.js"></script>
  <script src="/js/jquery.jside.menu.js"></script>
	<script>
	$(document).ready(function(){
	$(".menu-container").jSideMenu({
	    jSidePosition: "position-right",
	    jSideSticky: true,
	    jSideSkin: "endless-river",
	     });
	}); 
	</script>
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:300|Noto+Serif+SC&amp;display=swap">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4/css/font-awesome.min.css">
</head>
<body>
<div class="single">
<div id="page">
<div id="lx-aside" style="background-image: url(/images/page-cover.jpg)" data-stellar-background-ratio="0.5">
  <div class="overlay">
  <div class="page-title">
    <div class="avatar"><a href="/"><img src="/images/person_1.jpg"></a></div>
    <span>2020-01-13</span>
    <h2>大数据简介以及单机搭建</h2>
    <div class="tags"><i class="fa fa-tag"></i><a class="tag-link" href="/tags/bigdata/">bigdata</a></div>
    </div>
</div>
</div>
<div id="lx-main-content">
  <div class="lx-post">
    <div class="lx-entry padding">
      <div>
        <h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><p><strong>大数据特点</strong></p>
<p><code>5V特点：Volume（大量）、Velocity（高速）、Variety（多样）、Value（价值）Veracity（真实性）</code> </p>
<p><code>数据量级大</code>/<code>数据时效性|数据处理速度快</code>/<code>数据多样性</code>/<code>数据有价值-降噪</code></p>
<p><strong>大数据与传统的数据技术的差别</strong></p>
<p>  1、数据规模大：传统数据技术主要是利用现有存在关系性数据库中的数据，对这些数据进行分析、处理，找到一些关联，并利用数据关联性创造价值。这些数据的规模相对较小，可以利用数据库的分析工具处理。而大数据的数据量非常大，不可能利用数据库分析工具分析。</p>
<p>​    2、非结构化数据：传统数据主要在关系性数据库中分析，而大数据可以处理图像、声音、文件等非结构化数据。</p>
<p>3、处理方式不同：因为数据规模大、非结构化数据这两方面因素，导致大数据在分析时不能取全部数据做分析。大数据分析时如何选取数据?这就需要根据一些标签来抽取数据。所以大数据处理过程中，比传统数据增加了一个过程Stream。就是在写入数据的时候，在数据上打一个标签，之后在利用大数据的时候，根据标签抽取数据。</p>
<p><strong>大数据面临问题?</strong></p>
<p><code>存储</code>:单机存储有限,如何解决海量数据存储?</p>
<p><code>分析</code>:如何在合理时间范围内对数据完成节本运算?</p>
<p><strong>分布式</strong>:通常将<code>夸机器</code>/<code>跨进程</code>/<code>跨虚拟机</code>架构称为分布式架构,因为硬件垂直提升成本较高且不可控,相比较垂直提升硬件水平扩展成本较低,能够使得投入和产出趋近于线性.</p>
<h2 id="大数据分析方案哪些"><a href="#大数据分析方案哪些" class="headerlink" title="大数据分析方案哪些?"></a>大数据分析方案哪些?</h2><p><code>Map Reduce</code>:代表基于磁盘离线大数据静态批处理框架-延迟较高30分钟+</p>
<p><code>Spark</code>:代表基于内存近实时(离线)大数据静态批处理框架-几乎是Map Reduce的10~100倍速度</p>
<p><code>Storm|Spark Streaming| Flink|Kafka Stream</code>:实时的流(流程)处理框架,达到对记录级别的数据显示毫秒级处理.</p>
<h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><p>Hadoop是在2006年雅虎从Nutch(给予Java爬虫框架)工程中剥离一套分布式的解决方案.该方案参考了Goggle的<code>GFS(Google File System)</code>和MapReduce论文,当时发布的版本称为Hadoop-1.x,并且在2010年雅虎对Hadoop做又一次升级,该次升级的目的是优化了Hadoop的MapReduce框架,使得Hadoop更加易用,用户只需要少许配置,就可以使用hadoop实现海量数据存储和大规模数据集的分析.<code>一个由Apache基金会所开发的分布式系统基础架构。</code></p>
<p>==HDFS==: hadoop distribute filesysterm</p>
<p>==Map Reduce==:hadoop中的分布式计算框架,实现对海量数据并行分析和计算.</p>
<h2 id="Hadoop-Eco-System-hadoop的生态系统圈"><a href="#Hadoop-Eco-System-hadoop的生态系统圈" class="headerlink" title="Hadoop Eco System (hadoop的生态系统圈)"></a>Hadoop Eco System (hadoop的生态系统圈)</h2><p><code>HDFS</code>:分布式存储系统</p>
<p><code>mapreduce</code>:并行计算框架</p>
<p><code>hbase</code>:基于HDFS之上一款NoSQL数据库(名符其实海量数据存储解决方案)</p>
<p><code>hive</code>:会一款SQL的解析引擎,可以将SQL翻译成MapReduce任务,将任务提交给MapReduce框架.</p>
<p><code>flume</code>:分布式日志采集系统,用于搜集海量数据,并且存储到HDFS/Hbase.</p>
<p><code>Kafka</code>:分布式消息系统,实现分布系统间解耦和海量数据的缓冲.</p>
<p><code>zookeeper</code>:分布式协调服务,用于<code>服务注册中心</code>/<code>配置中心</code>/<code>集群选举</code>/<code>状态监测</code>/<code>分布式锁</code></p>
<h2 id="HDFS-环境搭建-伪分布式单机-测试"><a href="#HDFS-环境搭建-伪分布式单机-测试" class="headerlink" title="HDFS 环境搭建(伪分布式单机-测试)"></a>HDFS 环境搭建(伪分布式单机-测试)</h2><ul>
<li>Window 安装64 bit CentOS(需要额外开启Intel 虚拟化技术)</li>
</ul>
<ul>
<li><p>安装JDK</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">一</span><br><span class="line">1、查询要安装jdk的版本：</span><br><span class="line">命令：yum -y list java*</span><br><span class="line">2、安装jdk</span><br><span class="line">命令：yum install -y java-1.8.0-openjdk.x86_64</span><br><span class="line">3、查询jdk版本</span><br><span class="line">命令：java -version</span><br><span class="line">默认给安装到usr/lib/jvm/</span><br><span class="line">二、解压（常用）</span><br><span class="line"> rpm -ivh jdk-8u171-linux-x64.rpm</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装JDK配置<code>JAVA_HOME</code></p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile #系统变量</span><br><span class="line">[root@CentOS ~]# vi /root/.bashrc # 用户变量</span><br><span class="line">JAVA_HOME=/usr/java/latest</span><br><span class="line">PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">CLASSPATH=.</span><br><span class="line">export JAVA_HOME</span><br><span class="line">export PATH</span><br><span class="line">export CLASSPATH</span><br><span class="line">[root@CentOS ~]# source /root/.bashrc </span><br><span class="line">[root@CentOS ~]# jps</span><br><span class="line">1495 Jps</span><br></pre></td></tr></table></figure>

<blockquote>
</blockquote>
<blockquote>
<p>参考:<a href="https://blog.csdn.net/yuzongtao/article/details/44700927" target="_blank" rel="noopener">https://blog.csdn.net/yuzongtao/article/details/44700927</a></p>
</blockquote>
<ul>
<li>尝试<code>[root@CentOS ~]# yum install lrzsz -y</code>组件,如果用户将JAVA_HOME配置在系统变量中<code>/etc/profile</code>需要在安装hadoop时候额外配置<code>etc/hadoop/hadoop-env.sh</code>,因此推荐配置在用户变量中.</li>
<li>配置主机名和IP映射关系<code>/etc/hosts</code></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS ~]# vi /etc/hosts</span><br><span class="line">127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">192.168.169.139 CentOS</span><br></pre></td></tr></table></figure>

<blockquote>
<p>在分布式系统中很多服务都是以主机名标示节点,因此配置IP和主机名的映射关系.用户可以查看以下文件</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS ~]# cat /etc/sysconfig/network</span><br><span class="line">NETWORKING=yes</span><br><span class="line">HOSTNAME=CentOS</span><br></pre></td></tr></table></figure>

<ul>
<li>关闭防火墙服务centos6</li>
<li>centOS7关闭防火墙：<a href="https://blog.csdn.net/TTTZZZTTTZZZ/article/details/81483204" target="_blank" rel="noopener">https://blog.csdn.net/TTTZZZTTTZZZ/article/details/81483204</a></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS ~]# service iptables stop #关闭服务</span><br><span class="line">iptables: Setting chains to policy ACCEPT: filter [  OK  ]</span><br><span class="line">iptables: Flushing firewall rules: [  OK  ]</span><br><span class="line">iptables: Unloading modules: [  OK  ]</span><br><span class="line">[root@CentOS ~]# chkconfig iptables off #关闭开机自起</span><br><span class="line">[root@CentOS ~]# chkconfig --list | grep iptables </span><br><span class="line">iptables        0:off   1:off   2:off   3:off   4:off   5:off   6:off</span><br></pre></td></tr></table></figure>

<blockquote>
<p>因为搭建分布式服务之间可能会产生相互的调度,为了保证正常的通信,一般需要关闭防火墙.</p>
</blockquote>
<ul>
<li>配置主机SSH免密码认证(密匙)</li>
</ul>
<p>SSH 为 Secure Shell 的缩写，SSH 为建立在应用层基础上的安全协议，专为远程登录会话和其他网络服务提供安全性的协议。</p>
<p>==<em>基于口令的安全验证</em>==:基于口令<code>用户名</code>/<code>密码</code></p>
<p>==<em>基于密匙的安全验证</em>==:</p>
<p>需要依靠密匙，也就是你必须为自己创建一对密匙，并把公用密匙放在需要访问的服务器上。如果你要连接到SSH服务器上，客户端软件就会向服务器发出请求，请求用你的密匙进行安全验证。服务器收到请求之后，先在该服务器上你的主目录下寻找你的公用密匙，然后把它和你发送过来的公用密匙进行比较。如果两个密匙一致，服务器就用公用密匙加密“质询”（challenge）并把它发送给客户端软件。客户端软件收到“质询”之后就可以用你的私人密匙解密再把它发送给服务器。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS ~]# ssh-keygen -t rsa</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/root/.ssh/id_rsa): </span><br><span class="line">Created directory '/root/.ssh'.</span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">c3:b7:c4:e3:5e:6f:db:69:48:23:1e:f7:81:9b:d1:8e root@CentOS</span><br><span class="line">The key's randomart image is:</span><br><span class="line">+--[ RSA 2048]----+</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|                 |</span><br><span class="line">|       . .       |</span><br><span class="line">|        S =   o  |</span><br><span class="line">|         = = * o |</span><br><span class="line">|          + * X .|</span><br><span class="line">|         . o E.=.|</span><br><span class="line">|          .  .+o.|</span><br><span class="line">+-----------------+</span><br><span class="line">[root@CentOS ~]# ssh-copy-id CentOS</span><br><span class="line">The authenticity of host 'centos (192.168.169.139)' can't be established.</span><br><span class="line">RSA key fingerprint is f0:63:ed:d6:21:3b:b5:47:ad:e2:7f:98:bd:8f:54:94.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? `yes`</span><br><span class="line">Warning: Permanently added 'centos,192.168.169.139' (RSA) to the list of known hosts.</span><br><span class="line">root@centos's password:`****` </span><br><span class="line">Now try logging into the machine, with "ssh 'CentOS'", and check in:</span><br><span class="line"></span><br><span class="line">  .ssh/authorized_keys</span><br><span class="line"></span><br><span class="line">to make sure we haven't added extra keys that you weren't expecting.</span><br></pre></td></tr></table></figure>

<ul>
<li>HADOOP HDFS安装与配置</li>
</ul>
<blockquote>
<p>参考:<a href="http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html</a></p>
</blockquote>
<p><em>解压并且配置HADOOP_HOME</em></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS ~]# tar -zxf hadoop-2.6.0_x64.tar.gz -C /usr/</span><br><span class="line"></span><br><span class="line">HADOOP_HOME=/usr/hadoop-2.6.0</span><br><span class="line">JAVA_HOME=/usr/java/latest</span><br><span class="line">PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br><span class="line">CLASSPATH=.</span><br><span class="line">export JAVA_HOME</span><br><span class="line">export PATH</span><br><span class="line">export CLASSPATH</span><br><span class="line">export HADOOP_HOME</span><br><span class="line"></span><br><span class="line">[root@CentOS ~]# source /root/.bashrc </span><br><span class="line">[root@CentOS ~]# echo $HADOOP_HOME</span><br></pre></td></tr></table></figure>

<blockquote>
<p><code>HADOOP_HOME</code>环境变量被第三方产品所依赖例如:<code>hbase</code>/<code>hive</code>/<code>flume</code>/<code>Spark</code>在集成Hadoop的时候,是通过读取HADOOP_HOME环境变量确定HADOOP位置.</p>
</blockquote>
<p><em>配置etc/hadoop/core-site.xml</em></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://CentOS:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/hadoop-2.6.0/hadoop-$&#123;user.name&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><em>配置etc/hadoop/hdfs-site.xml</em></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p><em>配置etc/hadoop/slaves</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CentOS</span><br></pre></td></tr></table></figure>

<ul>
<li>启动HDFS</li>
</ul>
<p><em>1.如果是第一次启动HDFS,需要格式化<code>namenode</code></em></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS ~]# hdfs namenode -format</span><br><span class="line">...</span><br><span class="line">19/01/02 20:19:37 INFO common.Storage: Storage directory /usr/hadoop-2.6.0/hadoop-root/dfs/name has been successfully formatted.</span><br><span class="line">...</span><br><span class="line">再次启动需要删除/usr/hadoop-2.6.0/hadoop-root/</span><br></pre></td></tr></table></figure>

<blockquote>
<p>格式化成功后,用户可以看到以下目录结构</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1.安装插件 yum install -y tree</span><br><span class="line">[root@CentOS ~]# tree /usr/hadoop-2.6.0/hadoop-root/</span><br><span class="line">/usr/hadoop-2.6.0/hadoop-root/</span><br><span class="line">└── dfs</span><br><span class="line">    └── name</span><br><span class="line">        └── current</span><br><span class="line">            ├── fsimage_0000000000000000000</span><br><span class="line">            ├── fsimage_0000000000000000000.md5</span><br><span class="line">            ├── seen_txid</span><br><span class="line">            └── VERSION</span><br></pre></td></tr></table></figure>

<p><em>2.启动HDFS服务</em></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS ~]# start-dfs.sh </span><br><span class="line">Starting namenodes on [CentOS]</span><br><span class="line">CentOS: namenode running as process 1846. Stop it first.</span><br><span class="line">CentOS: starting datanode, logging to /usr/hadoop-2.6.0/logs/hadoop-root-datanode-CentOS.out</span><br><span class="line">Starting secondary namenodes [0.0.0.0]</span><br><span class="line">The authenticity of host '0.0.0.0 (0.0.0.0)' can't be established.</span><br><span class="line">RSA key fingerprint is f0:63:ed:d6:21:3b:b5:47:ad:e2:7f:98:bd:8f:54:94.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">0.0.0.0: Warning: Permanently added '0.0.0.0' (RSA) to the list of known hosts.</span><br><span class="line">0.0.0.0: starting secondarynamenode, logging to /usr/hadoop-2.6.0/logs/hadoop-root-secondarynamenode-CentOS.out</span><br><span class="line">[root@CentOS ~]# jps</span><br><span class="line">2370 Jps</span><br><span class="line">2133 DataNode</span><br><span class="line">1846 NameNode</span><br><span class="line">2267 SecondaryNameNode</span><br><span class="line">[root@CentOS ~]# stop-dfs.sh </span><br><span class="line">Stopping namenodes on [CentOS]</span><br><span class="line">CentOS: stopping namenode</span><br><span class="line">CentOS: stopping datanode</span><br><span class="line">Stopping secondary namenodes [0.0.0.0]</span><br><span class="line">0.0.0.0: stopping secondarynamenode</span><br></pre></td></tr></table></figure>

<blockquote>
<p>或者用户可以访问浏览器:<a href="http://192.168.169.139:50070" target="_blank" rel="noopener">http://192.168.169.139:50070</a></p>
<p><a href="https://www.cnblogs.com/zyanrong/p/11774997.html" target="_blank" rel="noopener">https://www.cnblogs.com/zyanrong/p/11774997.html</a></p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@CentOS ~]# hdfs dfs -put /root/jdk-8u171-linux-x64.rpm  /</span><br><span class="line">[root@CentOS ~]# hdfs dfs -ls  /</span><br><span class="line">Found 1 items</span><br><span class="line">-rw-r--r--   1 root supergroup  175262413 2019-01-02 20:29 /jdk-8u171-linux-x64.rpm</span><br></pre></td></tr></table></figure>

<blockquote>
</blockquote>

      </div>
    </div>
  </div>
</div>
<div class="lx-navigation">
	<div class="lx-cover prev lx-cover-sm" style="background-image: url(/images/footer_1.jpg)">
		<div class="overlay"></div>
		<a class="copy" href="/2020/01/16/hadoop之hdfs/">
			<div class="display-t">
				<div class="display-tc">
					<div>
						<span>Next</span>
						<h3>hadoop之hdfs</h3>
					</div>
				</div>
			</div>
		</a>
	</div>
        <div class="lx-cover next lx-cover-sm" style="background-image: url(/images/footer_2.jpg)">
		<div class="overlay"></div>
		<a class="copy" href="/2020/01/13/NoSql相关知识/">
			<div class="display-t">
				<div class="display-tc">
					<div>
						<span>Prev</span>
						<h3>NoSql相关知识</h3>
					</div>
				</div>
			</div>
		</a>
	</div>
</div>
</div>
<div class="comment"><div id="comments"></div></div>
<footer>
  <div>
  Copyright &copy; 2019.<a href="/">Black eight</a><br><img src="http://dchip-web.z-chip.com/download/2020-07-24/16.37.38/%E5%A4%87%E6%A1%88%E5%9B%BE%E6%A0%87.png">京公网安备 11010802032453号<br>
  </div>
</footer>
</div>
<a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i></a>
<div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Search..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>

<button class="menu-trigger"></button>
<div class="menu">
  <div class="menu-head">
    <span class="layer">
      <div class="col">
        <div class="row for-pic">
          <div class="profile-pic">
            <a href="/"><img src="/images/person_1.jpg" alt="WL"></a>
          </div>
        </div>
        <div class="row for-name">
          <p>WL</p>
          <span class="tagline">Mr. Worldwide I just want to welcome everybody to my life It's heaven on earth but it's one hell of a ride</span>
        </div>
      </div>
    </span>
  </div>
  <nav class="menu-container">
  <ul class="menu-items">
    <li><a href="/"><i class="fa fa-home fa-fw"></i>首页</a></li>
    <li><a href="/archives/"><i class="fa fa-archive fa-fw"></i>归档</a></li>
    <li class="has-sub"><span class="dropdown-heading">
      <i class="fa fa-bookmark fa-fw"></i>页面</span>
        <ul>
          <li><a href="/guestbook">留言</a></li>
        <li><a href="/about">关于</a></li>
        </ul>
    </li>
    <li class="has-sub"><span class="dropdown-heading">
      <i class="fa fa-link fa-fw"></i>友链</span>
        <ul>
          <li> <a href="https://lx.blleng.cn" target="_blank">Theme-Lx</a></li>
        </ul>
    </li>
  </ul>
  </nav>
</div>

<div class="gototop js-top">
  <a href="#" class="js-gotop"><i class="fa fa-arrow-up"></i></a>
</div>
<script src="/js/jquery.easing.min.js"></script>
<script src="/js/jquery.waypoints.min.js"></script>
<script src="/js/jquery.stellar.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/local.search.js"></script>
<script src="//unpkg.com/valine"></script>
<script>
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(function(item) {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'YFLRL95mJxOLxyHI5EKXlr4Q-gzGzoHsz',
    appKey: 'FO7iHJSy5vVqCIW3goFYWD5x',
    placeholder: '此处留言',
    avatar: 'identicon',
    meta: guest,
    pageSize: '10' || 10,
    lang: 'zh-cn' || 'zh-cn'
  });
</script>

</body>
</html>
